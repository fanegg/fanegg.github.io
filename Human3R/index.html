<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description" content="Human3R: Everyone Everywhere All at Once">
    <meta name="keywords" content="Human3R">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Human3R: Everyone Everywhere All at Once</title>

    <link rel="icon" type="image/x-icon" href="static/images/icon.png">
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVDSP8EYWQ"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-FVDSP8EYWQ');
    </script>

    <meta property="og:image" content="static/images/icon.png">
    <meta property="og:image:type" content="image/png">
    <meta property="og:type" content="website">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Human3R: Everyone Everywhere All at Once">
    <meta name="twitter:image" content="static/images/icon.png">
    <meta name="twitter:description"
        content="Human3R: Everyone Everywhere All at Once">
    <meta name="twitter:image" content="static/images/icon.png">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans:400,600|Noto+Sans:400,600|Castoro:400,600"
        rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/npm/modern-normalize@3.0.1/modern-normalize.min.css" rel="stylesheet" />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/tabler-icons/3.19.0/tabler-icons-outline.min.css"
        rel="stylesheet" />
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.8.2/css/bulma.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma-carousel@4.0.4/dist/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.7.4/css/bulma.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma-carousel@4.0.3/dist/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/index.js"></script>
    <style>
        .center-image {
            display: block;
            margin: 0 auto;
        }

        .item {
            margin: 10px;
        }

        .blend-img-background {
            mix-blend-mode: multiply;
        }

        button {
            display: block;
            width: 100%;
            padding: 10px 0;
            margin-top: 10px;
            cursor: pointer;
        }
 
        nav {
            text-align: center;
        }

        nav ul {
            list-style: none;
            padding: 0;
            margin: 20px auto;
            display: flex;
            justify-content: center;
            align-items: stretch;
            width: 100%;
            gap: 10px;
        }

        nav ul li {
            flex: 1;
            display: flex;
            margin: 0;
        }

        nav ul li a {
            display: flex;
            align-items: center;
            justify-content: center;
            background-color: #f5f5f5;
            color: #363636;
            padding: 10px 20px;
            text-decoration: none;
            border: none;
            border-radius: 5px;
            font-size: 16px;
            cursor: pointer;
            transition: background-color 0.3s ease, transform 0.2s ease;
            min-height: 50px;
            flex-grow: 1;
            box-sizing: border-box;
            overflow: hidden;
        }


        nav ul li a:hover {
            background-color: #e4e4e4;
            transform: scale(1.05);
        }

        nav ul li a:active {
            background-color: #d3d3d3;
            transform: scale(0.95);
        }

        nav ul li a.active {
            background-color: #cccccc;
            color: #000000;
        }


        .dynamic-section {
            display: block;
        }

        .panel-style {
            background-color: #fafafa;
            padding: 20px;
            margin: 20px auto;
            border: 1px solid #ccc;
            border-radius: 8px;
        }

        .thumbnail-container {
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 10px;
            margin: 20px auto 10px;
            max-width: 100%;
        }

        .video-container {
            position: relative;
            width: 98%;
            margin: 0 auto;
        }

        .video-labels {
            display: flex;
            justify-content: space-between;
            margin-top: auto;
            align-items: center;
        }

        .video-label {
            flex: 1;
            text-align: center;
            font-size: 16px;
            font-weight: bold;
        }

        .content-text {
            max-width: 90%;
            margin: 0 auto;
            text-align: justify;
        }

        .math-formula {
            max-width: 90%;
            margin: 0 auto;
            text-align: center;
        }
        /* custom colors for highlighted words */
        .freeze-blue { color: #1f78b4; }
        .learn-red { color: #d45c43; }
        #carousel-results {
            visibility: hidden;
        }
    </style>
</head>

<body>
    <section class="hero" style="margin-bottom: 0; padding-bottom: 0;">
        <div class="hero-body" style="padding-bottom: 1rem;">
            <div class="container is-max-desktop">
                <div class="columns is-centered" style="margin-bottom: 0">
                    <div class="column is-max-desktop has-text-centered">
                        <h1 class="title is-2 publication-title" style="margin-bottom:0rem; max-width: 85%; margin-left: auto; margin-right: auto;">
                            <img src="./static/images/icon.png" alt="ICON"
                                style="max-width: 96px; vertical-align: bottom;">
                            <strong>Human3R: Everyone Everywhere All at Once</strong>
                        </h1>
                    </div>
                </div>
                <div class="columns is-centered">
                    <div class="column is-four-fifths has-text-centered">
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://fanegg.github.io/">Yue 
                                    Chen</a><sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;
                            </span>
                            <span class="author-block">
                                <a href="https://rover-xingyu.github.io/">Xingyu 
                                    Chen</a><sup>1*</sup>&nbsp;&nbsp;&nbsp;&nbsp;
                            </span>
                            <span class="author-block">
                                <a href="https://yuxuan-xue.com/">Yuxuan 
                                    Xue</a><sup>2</sup>&nbsp;&nbsp;&nbsp;&nbsp;
                            </span>
                            <span class="author-block">
                                <a href="https://apchenstu.github.io/">Anpei 
                                    Chen</a><sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;
                            </span>
                            <span class="author-block">
                                <a href="https://xiuyuliang.cn/">Yuliang 
                                    Xiu</a><sup>1†</sup>&nbsp;&nbsp;&nbsp;&nbsp;
                            </span>
                            <span class="author-block">
                                <a href="https://virtualhumans.mpi-inf.mpg.de/">Gerard 
                                    Pons-Moll</a><sup>2,3</sup>&nbsp;&nbsp;&nbsp;&nbsp;
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>Westlake University</span>
                            &nbsp;&nbsp;&nbsp;&nbsp;
                            <span class="author-block"><sup>2</sup>University of Tübingen, Tübingen AI Center</span>
                            &nbsp;&nbsp;&nbsp;&nbsp;
                            <span class="author-block"><sup>3</sup>Max Planck Institute for Informatics</span>
                        </div>

                        <div class="is-size-6 publication-authors" style="margin-top: 0.5rem;">
                            <span class="author-block">*Project Lead</span>
                            &nbsp;&nbsp;&nbsp;&nbsp;
                            <span class="author-block">†Corresponding Author</span>
                        </div>

                        <!-- <br>
                        <div class="columns is-centered" style="margin-bottom: 0em">
                            <div class="column is-max-desktop has-text-centered">
                                <h1 class="title is-4 publication-title" style="margin-bottom:0rem">
                                    <h1 class="title is-4 publication-title" style="margin-bottom:0rem">
                                        <strong><img src="static/images/palm-tree_1f334.png" style="width: 1em; height: 1em; vertical-align: top;">arXiv 2025<img src="static/images/coconut_1f965.png" style="width: 1em; height: 1em; vertical-align: top;"></strong>
                                    </h1>
                                </h1>
                            </div>
                        </div> -->

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2510.xxxxx" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://github.com/fanegg/Human3R" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="interactive.html" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <svg xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 0 512 512"
                                                style="fill: #ffdf0f">
                                                <path
                                                    d="M256 0c-25.3 0-47.2 14.7-57.6 36c-7-2.6-14.5-4-22.4-4c-35.3 0-64 28.7-64 64V261.5l-2.7-2.7c-25-25-65.5-25-90.5 0s-25 65.5 0 90.5L106.5 437c48 48 113.1 75 181 75H296h8c1.5 0 3-.1 4.5-.4c91.7-6.2 165-79.4 171.1-171.1c.3-1.5 .4-3 .4-4.5V160c0-35.3-28.7-64-64-64c-5.5 0-10.9 .7-16 2V96c0-35.3-28.7-64-64-64c-7.9 0-15.4 1.4-22.4 4C303.2 14.7 281.3 0 256 0zM240 96.1c0 0 0-.1 0-.1V64c0-8.8 7.2-16 16-16s16 7.2 16 16V95.9c0 0 0 .1 0 .1V232c0 13.3 10.7 24 24 24s24-10.7 24-24V96c0 0 0 0 0-.1c0-8.8 7.2-16 16-16s16 7.2 16 16v55.9c0 0 0 .1 0 .1v80c0 13.3 10.7 24 24 24s24-10.7 24-24V160.1c0 0 0-.1 0-.1c0-8.8 7.2-16 16-16s16 7.2 16 16V332.9c-.1 .6-.1 1.3-.2 1.9c-3.4 69.7-59.3 125.6-129 129c-.6 0-1.3 .1-1.9 .2H296h-8.5c-55.2 0-108.1-21.9-147.1-60.9L52.7 315.3c-6.2-6.2-6.2-16.4 0-22.6s16.4-6.2 22.6 0L119 336.4c6.9 6.9 17.2 8.9 26.2 5.2s14.8-12.5 14.8-22.2V96c0-8.8 7.2-16 16-16c8.8 0 16 7.1 16 15.9V232c0 13.3 10.7 24 24 24s24-10.7 24-24V96.1z">
                                                </path>
                                            </svg>
                                        </span>
                                        <span><strong>Play NOW</strong></span>
                                    </a>
                                </span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <section class="hero teaser">
        <div class="container fluid">
            <div class="hero-body is-max-widescreen">
                <div class="columns is-centered">
                    <div class="column is-centered is-two-thirds">
                        <div class="notification is-centered is-info is-rounded"
                            style="text-align: center; padding-bottom: 5px; padding-top: 5px; background-color: #D9A7B3; border-radius: 10px;">
                            <h6 class="title is-2 publication-title" style="margin-bottom:0rem; text-align: center; color:#ffffff; font-size: 20px; margin-left: auto; margin-right: auto;">
                                <p>Inference with One model, One stage;
                                Training in One day using One GPU</p>
                            </h6>
                        </div>
                    </div>
                </div>
                <center>
                    <video id="teaser" preload="auto" autoplay muted loop playsinline width="100%"
                        style="display: block; margin-top: 0; margin-bottom: 0;">
                        <source src="./static/videos/teaser.mp4" type="video/mp4">
                    </video>
                </center>
            </div>
        </div>
    </section>


    <section class="section has-background-light">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            We present Human3R, a unified, feed-forward framework for online 4D human-scene reconstruction, in the world frame, from casually captured monocular videos.
                            Unlike previous approaches that rely on multi-stage pipelines, iterative contact-aware refinement between humans and scenes, and heavy dependencies, e.g., human detection, depth estimation, and SLAM pre-processing, Human3R jointly recovers global multi-person SMPL-X bodies (<em>"everyone"</em>), dense 3D scene (<em>"everywhere"</em>), and camera trajectories in a single forward pass (<em>"all-at-once"</em>).
                            Our method builds upon the 4D online reconstruction model CUT3R, and uses parameter-efficient visual prompt tuning, to strive to preserve CUT3R's rich spatiotemporal priors, while enabling direct readout of multiple SMPL-X bodies. 
                            Human3R is a <strong>unified model</strong> that eliminates heavy dependencies and iterative refinement. After being trained on the relatively small-scale synthetic dataset BEDLAM for just <strong>one day</strong> on <strong>one GPU</strong>, it achieves superior performance with remarkable efficiency:
                            it reconstructs multiple humans in a <strong>one-shot</strong> manner, along with 3D scenes, in <strong>one stage</strong>, at real-time speed (15 FPS) with a low memory footprint (8 GB).
                            Extensive experiments demonstrate that Human3R delivers state-of-the-art or competitive performance across tasks, including global human motion estimation, local human mesh recovery, video depth estimation, and camera pose estimation, with a single unified model. 
                            We hope that Human3R will serve as a simple yet strong baseline, be easily extended for downstream applications. 
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section" style="padding-top: 2rem;">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Online Human-Scene Reconstruction</h2>
                    <p style="max-width: 100%; margin: 0 auto; margin-bottom: 0px; text-align: center;">
                        Given a stream of RGB images, Human3R continuously reconstructs 4D human-scene in real time, online estimating multi-person meshes, camera parameters, and dense 3D geometry within each frame.
                    </p>
            </div>
        </div>

        <script defer src="./static/js/pts-vis.js"></script>
        <section id="pts-vis" class="section dynamic-section" style="padding-top: 0rem;">
        </section>
    </section>
    

    <section class="section" style="padding-top: 0rem;">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Method Overview</h2>
                    <div class="content has-text-centered">
                        <div>
                            <img src="./static/images/fig_pipe.png" alt="Reconstruction"
                                class="blend-img-background center-image" width="100%" loading="lazy" />
                        </div>
                        <div class="content has-text-justified" style="margin-top: 15px;">
                            <p>
                                Human3R enables online human-scene reconstruction from video streams.
                                Each frame is encoded into image tokens, with patch-level detection.
                                Each detected head token, concatenated with a human prior token from Multi-HMR ViT-DINO feature, is projected into a <em>human prompt</em>.
                                The <em>human prompts</em> serve as discriminative human-ID queries for the decoder: they self-attend with image tokens to aggregate spatial whole-body information and cross-attend with the scene state to retrieve temporally consistent human tokens within the 3D scene context.
                                Only human-related layers are <span class="learn-red">fine-tuned</span>, other parameters remain <span class="freeze-blue">frozen</span> and are initialized from CUT3R.
                            </p>
                        </div>
                </div>
            </div>
        </div>
    </section>


    <section class="section" style="padding-top: 2rem;">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Comparison with Ground-truth</h2>
                    <p style="max-width: 100%; margin: 0 auto; margin-bottom: 0px; text-align: center;">
                        We compare our model prediction with the ground-truth global human motion and camera poses.
                    </p>
            </div>
        </div>
        <script defer src="./static/js/vs-gt.js"></script>
        <section id="vs-gt" class="section dynamic-section" style="padding-top: 0rem;">
        </section>
    </section>


    <section class="section" style="padding-top: 0rem;">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Failure Cases</h2>
                    <p style="max-width: 100%; margin: 0 auto; margin-bottom: 0px; text-align: center;">
                        <strong>Failure case 1:</strong> Human3R offers coarse human-scene interactions that may exhibit penetration, which can be refined through contact-aware iterative optimization. 
                        <strong>Failure case 2:</strong> Opportunities exist for more expressive designs to handle human-object interactions.
                    </p>
            </div>
        </div>
        <script defer src="./static/js/failure.js"></script>
        <section id="failure" class="section dynamic-section" style="padding-top: 0rem;">
        </section>
    </section>


    <section class="section" style="padding-top: 0rem;">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Related Work</h2>
                    <div class="content has-text-justified">
                        <li><a href="https://cut3r.github.io/">CUT3R: Continuous 3D Perception Model with Persistent State</a></li>
                        <li><a href="https://rover-xingyu.github.io/TTT3R/">TTT3R: 3D Reconstruction as Test-Time Training</a></li>
                        <li><a href="https://arxiv.org/abs/2402.14654">Multi-HMR: Multi-Person Whole-Body Human Mesh Recovery in a Single Shot</a></li>
                        <li><a href="https://yufu-wang.github.io/phmr-page/">PromptHMR: Promptable Human Mesh Recovery</a></li>
                        <li><a href="https://yufu-wang.github.io/tram4d/">TRAM: Global Trajectory and Motion of 3D Humans from in-the-wild Videos</a></li>
                        <li><a href="https://zju3dv.github.io/gvhmr/">World-Grounded Human Motion Recovery via Gravity-View Coordinates</a></li>
                        <li><a href="https://genforce.github.io/JOSH/">Joint Optimization for 4D Human-Scene Reconstruction in the Wild</a></li>
                        <li><a href="https://bedlam.is.tue.mpg.de/">BEDLAM: A Synthetic Dataset of Bodies Exhibiting Detailed Lifelike Animated Motion</a></li>
                      </div>
                </div>
            </div>
        </div>
    </section>


    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Acknowledgements</h2>
                    <div class="content has-text-justified">
                        Thank all members of Endless AI, Inception3D and RVH Group for their help and discussion, and Yiru for creating the fantastic logo — love it!
                        Yue and Xingyu are funded by the Westlake Education Foundation.
                        Gerard and Yuxuan are funded by the Carl Zeiss Foundation, the DFG - 409792180 (EmmyNoether Programme, project: Real Virtual Humans), and the BMBF: Tübingen AI Center, FKZ: 01IS18039A.
                        Gerard is a member of the Machine Learning Cluster of Excellence, EXC number 2064/1 - Project number 390727645.
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- <section class="section" id="BibTeX">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-justified">
                <div class="column is-four-fifths">

                    <h2 class="title">BibTeX</h2>
                    <pre><code>
    @article{chen2025human3r,
        title={Human3R: Everyone Everywhere All at Once},
        author={Chen, Yue and Chen, Xingyu and Xue, Yuxuan and Chen, Anpei and Xiu, Yuliang and Gerard, Pons-Moll},
        journal={arXiv preprint arXiv:2510.xxxxx},
        year={2025}
        }
                    </code></pre>

                </div>
            </div>
        </div>
    </section> -->


    <footer class="footer" style="background-color: transparent; padding-top: 2rem; padding-bottom: 2rem;">
        <div align="center" class="container">
            <div class="columns is-centered">
                <div class="content">
                    Design borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
                </div>
            </div>
        </div>
    </footer>

    <script>
    document.addEventListener('DOMContentLoaded', function() {
        document.getElementById('nav1').classList.add('active');
        showSection('vs_mon');
        loadComparisonIframes('mon');
    });

    Element.prototype.contains = function(text) {
        return this.textContent.includes(text);
    };
    </script>
</body>

</html>
