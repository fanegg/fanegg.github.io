<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>UV Volumes for Real-time Rendering of Editable Free-view Human Performance</title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> 
  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h2> UV Volumes for Real-time Rendering of Editable Free-view Human Performance</h2>
            <h4 style="color:#5a6268;">CVPR 2023</h4>
            <hr>
            <h6> <a href="https://scholar.google.com/citations?user=M2hq1_UAAAAJ&hl=en" target="_blank">Yue Chen</a><sup>1*</sup>, 
                <a href="https://scholar.google.com/citations?user=h-3xd3EAAAAJ&hl=en" target="_blank">Xuan Wang</a><sup>2,3*</sup>,
                <a href="https://scholar.google.com/citations?user=gDHPrWEAAAAJ&hl=en" target="_blank">Xingyu Chen</a><sup>1</sup>,
                <a href="https://scholar.google.com/citations?user=2vFjhHMAAAAJ&hl=en" target="_blank">Qi Zhang</a><sup>3</sup>, 
                <a href="https://scholar.google.com/citations?user=Dt0PcAYAAAAJ&hl=en" target="_blank">Xiaoyu Li</a><sup>3</sup>,
                <a href="https://scholar.google.com/citations?user=OemeiSIAAAAJ&hl=en" target="_blank">Yu Guo</a><sup>1‚Ä†</sup>, 
                <a href="https://scholar.google.com/citations?user=Bt4uDWMAAAAJ&hl=en">Jue Wang</a><sup>3</sup>, 
                <a href="https://scholar.google.com/citations?user=uU2JTpUAAAAJ&hl=en">Fei Wang</a><sup>1</sup></h6>
            <p>
                <sup>*</sup>Equal Contribution &nbsp;&nbsp; 
                <sup>‚Ä†</sup>Corresponding Author &nbsp;&nbsp; 
                <sup>1</sup>Xi'an Jiaotong University &nbsp;&nbsp; 
                <sup>2</sup>Ant Group &nbsp;&nbsp; 
                <sup>3</sup>Tencent AI Lab</p>
            <div class="row justify-content-center">
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_UV_Volumes_for_Real-Time_Rendering_of_Editable_Free-View_Human_Performance_CVPR_2023_paper.pdf" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Paper</a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/fanegg/UV-Volumes" role="button"  target="_blank">
                    <i class="fa fa-github-alt"></i> Code</a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chen_UV_Volumes_for_CVPR_2023_supplemental.pdf" role="button"  target="_blank">
                    <i class="fa fa-file-pdf-o"></i> Supplementary</a> </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
            <hr style="margin-top:0px">
            <img class="img-fluid" src="images/teaser.jpg">
          <p class="text-justify">Neural volume rendering enables photo-realistic renderings of a human performer in free-view, a critical task in immersive VR/AR applications. But the practice is severely limited by high computational costs in the rendering process. To solve this problem, we propose the UV Volumes, a new approach that can render an editable free-view video of a human performer in real-time. It separates the high-frequency (i.e., non-smooth) human appearance from the 3D volume, and encodes them into 2D neural texture stacks (NTS). The smooth UV volumes allow much smaller and shallower neural networks to obtain densities and texture coordinates in 3D while capturing detailed appearance in 2D NTS. For editability, the mapping between the parameterized human model and the smooth texture coordinates allows us a better generalization on novel poses and shapes. Furthermore, the use of NTS enables interesting applications, e.g., retexturing. Extensive experiments on CMU Panoptic, ZJU Mocap, and H36M datasets show that our model can render 960 x 540 images in 30FPS on average with comparable photo-realism to state-of-the-art methods.</p>
        </div>
      </div>
    </div>
  </section>

  
    <!-- youtube -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
<!--             <h3>Overview video</h3>
            <hr style="margin-top:0px"> -->
            <div class="embed-responsive embed-responsive-16by9">
                <!-- <iframe width="100%" playsinline="" src="https://www.youtube.com/embed/v3PsN-rMAUw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->
                <iframe width="100%" playsinline="" src="https://www.youtube.com/embed/JftQnXLMmPc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
              </div>
        </div>
      </div>
    </div>
  </section>
  <br>
  
  
    <!-- main -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Demo</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/main.mp4" type="video/mp4">
              </video>
              <!-- <br><br> -->
          <p class="text-justify">  </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- pipeline -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Pipeline</h3>
            <hr style="margin-top:0px">
            <img width="95%" class="img-fluid" src="images/pipe.jpg">
          <p class="text-justify">Our model has two main branches: 1) Based on a human pose ùúÉ, a volume generator constructs UV volumes involving the feature of UV information. Then a feature map can be rendered via differentiable raymarching and decoded to texture coordinates (UV) pixel-by-pixel. 2) A texture generator produces a pose-dependent Neural Texture Stack(NTS) ùìî that encodes the highly-detailed appearance information. The UV coordinates and the texture embedding interpolated from NTS are passed into an MLP to predict the color at the desired ray direction ùêù.</p>
        </div>
      </div>
    </div>
  </section>

  
  <!-- Novel View Synthesis of Dynamic Human -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Novel view synthesis of dynamic human</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/dynamic1.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/dynamic2.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/dynamic3.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/dynamic4.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/dynamic5.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/dynamic6.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/dynamic7.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/dynamic8.mp4" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- Novel view synthesis -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Novel view synthesis</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/novel_view1.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/novel_view2.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/novel_view3.mp4" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br>
  
  <!-- Repose -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Repose</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/repose1.mp4" type="video/mp4">
              </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/repose2.mp4" type="video/mp4">
              </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/repose3.mp4" type="video/mp4">
              </video>
              <!-- <br><br> -->
          <p class="text-justify">  </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- Reshape -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Reshape</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/reshape1.mp4" type="video/mp4">
              </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/reshape2.mp4" type="video/mp4">
              </video>
              <!-- <br><br> -->
          <p class="text-justify">  </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- Retexture -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Retexture</h3>
            <hr style="margin-top:0px">
<!--             <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/retexture1.mp4" type="video/mp4"> -->
              </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/retexture2.mp4" type="video/mp4">
              </video>
              <!-- <br><br> -->
          <p class="text-justify">  </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- citing -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>@inproceedings{chen2023uv,
  title={UV Volumes for real-time rendering of editable free-view human performance},
  author={Chen, Yue and Wang, Xuan and Chen, Xingyu and Zhang, Qi and Li, Xiaoyu and Guo, Yu and Wang, Jue and Wang, Fei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16621--16631},
  year={2023}
}</code></pre>
          <hr>
      </div>
    </div>
  </div>

  <footer class="text-center" style="margin-bottom:10px">
      Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template.
  </footer>

</body>
</html>
