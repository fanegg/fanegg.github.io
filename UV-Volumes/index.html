<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>UV Volumes for Real-time Rendering of Editable Free-view Human Performance</title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> 
  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h2> UV Volumes for Real-time Rendering of Editable Free-view Human Performance</h2>
            <h4 style="color:#5a6268;">arXiv 2022</h4>
            <hr>
            <h6> <a href="https://github.com/fanegg/" target="_blank">Yue Chen</a><sup>1</sup>, 
                <a href="https://github.com/XuanWangCV/" target="_blank">Xuan Wang</a><sup>2</sup>,
                <a href="https://fanegg.github.io/UV-Volumes/" target="_blank">Qi Zhang</a><sup>2</sup>, 
                <a href="https://xiaoyu258.github.io/" target="_blank">Xiaoyu Li</a><sup>2</sup>,
                <a href="https://github.com/rover-xingyu/" target="_blank">Xingyu Chen</a><sup>1</sup>,
                <a href="https://fanegg.github.io/UV-Volumes/" target="_blank">Yu Guo</a><sup>1</sup>, 
                <a href="https://fanegg.github.io/UV-Volumes/" target="_blank">Jue Wang</a><sup>2</sup>, 
                <a href="https://fanegg.github.io/UV-Volumes/" target="_blank">Fei Wang</a><sup>1</sup></h6>
            <p><sup>1</sup>Xi'an Jiaotong University &nbsp;&nbsp; 
                <sup>2</sup>Tencent AI Lab</p>
            <div class="row justify-content-center">
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://arxiv.org/pdf/2203.14402.pdf" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Paper</a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/fanegg/UV-Volumes" role="button"  target="_blank">
                    <i class="fa fa-github-alt"></i> Code</a> </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
            <hr style="margin-top:0px">
            <img class="img-fluid" src="images/teaser.png">
          <p class="text-justify"> Neural volume rendering has been proven to be a promising method for efficient and photo-realistic rendering of a human performer in free-view, a critical task in many immersive VR/AR applications. However, existing approaches are severely limited by their high computational cost in the rendering process. To solve this problem, we propose the UV Volumes, an approach that can render an editable free-view video of a human performer in real-time. It is achieved by removing the high-frequency (i.e., non-smooth) human textures from the 3D volume and encoding them into a 2D neural texture stack (NTS). The smooth UV volume allows us to employ a much smaller and shallower structure for 3D CNN and MLP, to obtain the density and texture coordinates without losing image details. Meanwhile, the NTS only needs to be queried once for each pixel in the UV image to retrieve its RGB value. For editability, the 3D CNN and MLP decoder can easily fit the function that maps the input structured-and-posed latent codes to the relatively smooth densities and texture coordinates. It gives our model a better generalization ability to handle novel poses and shapes. Furthermore, the use of NST enables new applications, e.g., retexturing. Extensive experiments on CMU Panoptic, ZJU Mocap, and H36M datasets show that our model can render 900 Ã— 500 images in 40 fps on average with comparable photorealism to state-of-the-art methods.</p>
        </div>
      </div>
    </div>
  </section>


  <!-- pipeline -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Pipeline</h3>
            <hr style="margin-top:0px">
            <img width="95%" class="img-fluid" src="images/pipe.png">
          <p class="text-justify"> Our model has two main branches: 1) Based on a human pose &theta;, a volume generator constructs UV volumes involving the feature of UV information. Then a feature map can be rendered via differentiable raymarching and decoded to texture coordinates (UV) pixel-by-pixel. 2) A texture generator produces a pose-dependent NTS encoding the highly-detailed appearance information. The UV coordinates and the texture embedding interpolated by it are passed into an MLP to predict spherical harmonic coefficients &eta;. The final color can be calculated by summing the weighted spherical harmonic bases evaluated at the desired ray direction.</p>
        </div>
      </div>
    </div>
  </section>

  
  <!-- Novel View Synthesis of Dynamic Human -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Novel View Synthesis of Dynamic Human</h3>
            <hr style="margin-top:0px">
            <h4 style="margin-top:20px; margin-bottom:20px; color:#717980">Results on CMU Panoptic Dataset</h4>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/dynamic_human_cmu.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/360dynamic_human_cmu.mp4" type="video/mp4">
            </video>
            <h4 style="margin-top:20px; margin-bottom:20px; color:#717980">Results on ZJU-Mocap Dataset</h4>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/dynamic_human_zju.mp4" type="video/mp4">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/360dynamic_human_zju.mp4" type="video/mp4">
            </video>
            </video>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- Novel View Synthesis -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Novel View Synthesis</h3>
            <hr style="margin-top:0px">
            <h4 style="margin-top:20px; margin-bottom:20px; color:#717980">Pose 1</h4>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/novelview_1.mp4" type="video/mp4">
            </video>
            <h4 style="margin-top:20px; margin-bottom:20px; color:#717980">Pose 2</h4>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/novelview_2.mp4" type="video/mp4">
            </video>
            </video>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- Free-view Video Synthesis
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Free-view Video Synthesis</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/free-view.mp4" type="video/mp4">
              </video>
              <!-- <br><br> -->
          <p class="text-justify">  </p>
        </div>
      </div>
    </div>
  </section>
  <br> -->

  <!-- Predicted Texture Stacks -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Predicted Texture Stacks</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/texture.mp4" type="video/mp4">
              </video>
              <!-- <br><br> -->
          <p class="text-justify">  </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- Reposing -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Reposing</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/reposing.mp4" type="video/mp4">
              </video>
              <!-- <br><br> -->
          <p class="text-justify">  </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- Reshaping -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Reshaping</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/reshaping.mp4" type="video/mp4">
              </video>
              <!-- <br><br> -->
          <p class="text-justify">  </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- Retexturing -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Retexturing</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/retexturing1.mp4" type="video/mp4">
              </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="images/retexturing2.mp4" type="video/mp4">
              </video>
              <!-- <br><br> -->
          <p class="text-justify">  </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- citing -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>@misc{chen2022uvvolumes,
      title={UV Volumes for Real-time Rendering of Editable Free-view Human Performance}, 
      author={Yue Chen and Xuan Wang and Qi Zhang and Xiaoyu Li and Xingyu Chen and Yu Guo and Jue Wang and Fei Wang},
      year={2022},
      eprint={2203.14402},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}</code></pre>
          <hr>
      </div>
    </div>
  </div>

  <footer class="text-center" style="margin-bottom:10px">
      Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template.
  </footer>

</body>
</html>
